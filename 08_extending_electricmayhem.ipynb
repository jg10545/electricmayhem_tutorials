{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b2930f7-a23d-4710-a793-3fc25da3dd22",
   "metadata": {},
   "source": [
    "# Tutorial 08: Extending `electricmayhem`\n",
    "\n",
    "All of the pipeline stages are subclasses from `PipelineBase`, which in turn inherits from `torch.nn.Module`- so our best practice should be to default to following the best practices for `torch.nn`. I recommend reading their documentation before you start.\n",
    "\n",
    "A word on memory management- any attributes added to your object as a parameter (`torch.nn.Parameter`, `torch.nn.ParameterDict`, etc) or as a module will get copied over to the GPU when you call `.cuda()`. If you create an attribute that's just a list of tensors or something it will not. If you're creating a pipeline stage that has a high memory footprint (such as an implanter designed for a large dataset) consider the tradeoff between storing more data on the GPU versus the overhead of copying over a subset each batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055c38fe-fd06-4f3f-a662-4b16011d93c4",
   "metadata": {},
   "source": [
    "### Required steps\n",
    "\n",
    "* Add a `name` attribute that's a string, giving the name of the module (how it will apear in MLFlow for example)\n",
    "* Add an `__init__()` method that starts with a call to `super().__init__()`. This is a requirement from `torch.nn` that sets up a bunch of the machinery the `Module` object relies on.\n",
    "* Any keyword arguments you need to re-initialize the step should be captured in a JSON/YAML-serializable dict in `self.params`.\n",
    "* The main behavior for the stage should be written as a `forward()` method that:\n",
    "  * Inputs the outputs of the previous stage (generally a batch of image tensors or a dictionary of image batches)\n",
    "  * Has an `evaluate` kwarg; if `evaluate=True` it runs an evaluation batch (for example possibly using holdout images or a separate model)\n",
    "  * Has a `control` kwarg; if `control=True`, runs a control batch (same configuration as previous batch but without the patch). Only needs to work with `evaluate=True).\n",
    "  * Can optionally input a dictionary of paramaters to the `params` kwarg, overruling any randomly-sampled parameters with these values.\n",
    "  * Can input `**kwargs` dictionary containing arbitrary metadata created by previous stages\n",
    "  * Returns a 2-tuple containing that stages' output and the input `kwargs` dictionary (possibly with more information added to it)\n",
    "* There should be a `get_last_sample_as_dict()` method. It should return any stochastic parameters sampled for the last batch as a dictionary containing lists or 1D `numpy` arrays of length `batchsize`. You should be able to pass this dictionary directly back to the `params` argument of `forward`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7ad9bb-6b02-4ae5-bc82-e1cc3c57036b",
   "metadata": {},
   "source": [
    "### Optional steps\n",
    "\n",
    "If you want to get fancy:\n",
    "\n",
    "* Override the `get_description()` method to generate a more useful markdown description for MLFlow.\n",
    "* Override the `log_vizualizations()` method with any diagnostics that would be useful to log to TensorBoard. This method will get called whenever `pipeline.evaluate()` is run. It should input:\n",
    "  * **x:** batch of evaluation data (usually a batch of image tensors; sometimes a dict of image batches)\n",
    "  * **x_control:** the corresponding control batch for **x** (for before-and-after visualizations)\n",
    "  * **writer:** a TensorBoard `SummaryWriter` object- use this to write diagnostics\n",
    "  * **step:** integer; current training step (needed both for TensorBoard and logging MLFlow metrics)\n",
    "  * **logging_to_mlflow:** Boolean; whether MLFlow logging is active.\n",
    "* Overwrite the `validate()` method to check for anything specific that could go wrong with that step. When the user calles `Pipeline.validate()` it will run the `validate()` method for each step. Use the `logging` library to record check results at the `info` or `warning` level. `validate()` inputs:\n",
    "  * **x:** batch of evaluation data (usually a batch of image tensors; sometimes a dict of image batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b449d8-4461-4032-9602-f30b4fc470d5",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "class MyPipelineStage(PipelineBase):\n",
    "    name = \"MyPipelineStage\"\n",
    "\n",
    "    def __init__(self, foo, bar):\n",
    "        super().__init__()\n",
    "        self.params = {\"foo\":foo, \"bar\":bar}\n",
    "        \n",
    "    def forward(self, x, control=False, evaluate=False, params=None, **kwargs):\n",
    "        <stuff here>\n",
    "        y = f(x)\n",
    "        return y, kwargs\n",
    "        \n",
    "    def get_last_sample_as_dict(self):\n",
    "        return dict(<some stuff>)\n",
    "        \n",
    "    def log_vizualizations(self, x, x_control, writer, step):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        writer.add_image(\"stacked_patch\", <some stuff>, global_step=step,\n",
    "                        logging_to_mlflow)\n",
    "         \n",
    "    def get_description(self):\n",
    "        return \"**MyPipelineStage** and some details that would be helpful in mlflow\"\n",
    "        \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f0c7e4-3ccc-47cf-8ee6-26cdb257e139",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
