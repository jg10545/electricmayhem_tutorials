{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87c26d84-d3a8-445f-9250-cd1c6eef2c58",
   "metadata": {},
   "source": [
    "# Tutorial 06: ensembles and transfer attacks\n",
    "\n",
    "Let's train some patches against an ensemble of two models and evaluate performance against a third."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae98af7-ab14-45f6-9ad1-3584d28509d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb6463b-d9e9-4bdf-b393-7e0c49a0b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import electricmayhem.whitebox as em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b515f2d-27b6-4fe2-8b49-e6e88c6055c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_CLASSES = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',\n",
    "                'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench','bird', 'cat',\n",
    "                'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',\n",
    "                'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "                 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "                'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "                 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',\n",
    "                'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "                'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book',\n",
    "                'clock', 'vase', 'scissors', 'teddy bear', 'hair drier','toothbrush']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddc4dc5-9c1a-4483-a24e-552d942c4dd7",
   "metadata": {},
   "source": [
    "## create\n",
    "\n",
    "Let's do color patches this time, but use a soft proofer during training to make sure the colors are realistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f122f04-2541-459c-8643-f6712d6bb72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "proofer = em.SoftProofer(\"data/profile.icc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1850c70d-2aeb-49c2-ba01-25a6a10cd4ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91c3e04f-d946-4efa-9175-e34ca48b8760",
   "metadata": {},
   "source": [
    "## implant\n",
    "\n",
    "Reuse the same target dataset from tutorial 01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12147874-2a06-4260-99b1-f0dd118a2739",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"data/toycar/toycar_warp_dataset.csv\")\n",
    "labels = labels[labels.patch != \"ground\"]\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b46bbe-bba5-4d59-9989-e0950fb1f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9980c810-5547-4851-adac-1f29bfce8330",
   "metadata": {},
   "source": [
    "Names of the 3 patches we'll train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6f0eca-bb1f-4aa9-8523-0a5ddb92db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.patch.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba60f27e-c516-4c7a-9885-7f079a59988d",
   "metadata": {},
   "source": [
    "The `em.WarpPatchImplanter()` class will take care of differentiably deforming and implanting patches (with kornia doing most of the heavy lifting). We need two inputs:\n",
    "\n",
    "* the `DataFrame` of target labels\n",
    "* a dictionary of patch shapes (at the point of implanting, so they'll be 3-channel); the implanter will use this to precompute transformation matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567738a3-b66a-4eb6-a51a-0c748c0b8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_shapes = {k:(3,64,64) for k in ['hood', 'roof', 'door']}\n",
    "imp = em.WarpPatchImplanter(labels, patch_shapes=patch_shapes, dataset_name=\"toycar_warp_no_ground\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110320de-c592-4b0e-a4a4-c7d580f977f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8499553-ae01-4f9e-bc4e-14e707371c14",
   "metadata": {},
   "source": [
    "## compose\n",
    "\n",
    "The main tool `electricmayhem` has so far is `em.KorniaAugmentationPipeline()`, which just wraps the `kornia.augmentation` API. Initialize it with a dictionary of image augmentations, where each value is the keyword arguments that augmentation takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f468ee-8800-43e8-aaa6-c74d656a704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = em.KorniaAugmentationPipeline({\"ColorJiggle\":{\"brightness\":0.2, \"contrast\":0.2, \"hue\":0.1, \"saturation\":0.1},\n",
    "                                    \"RandomAffine\":{\"scale\":(0.9,1.1), \"shear\":10, \"padding_mode\":\"reflection\", \"degrees\":0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfaa816-0c15-4e3f-849e-2f15768a3cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65122add-2036-4cb1-ae09-ec2221c491b5",
   "metadata": {},
   "source": [
    "## infer\n",
    "\n",
    "Here's where we'll depart from tutorial 01. Let's train a patch using two YOLOv8 models and test performance on a YOLOv11.\n",
    "\n",
    "The `em.YOLOWrapper` class can be run with a single model, separate models for training and evaluation, or dictionaries of training and evaluation models. If you pass an ensemble of models as a dictionary, the output of this stage will be a dictionary as well, so your loss function can handle the individual model outputs separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e8667c-6c48-4130-9473-7000bde4b6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov8n = ultralytics.YOLO(\"yolov8n.pt\").model.eval()\n",
    "yolov8s = ultralytics.YOLO(\"yolov8s.pt\").model.eval()\n",
    "yolov11n = ultralytics.YOLO(\"yolo11n.pt\").model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1116eb5e-8142-4b61-a585-a1038ea9173f",
   "metadata": {},
   "source": [
    "Pass dictionaries to `em.YOLOWrapper` to associate each model with a name (to make sure our logs are interpretable) as well as a YOLO version. In this case it won't matter because output formats of v8 and v11 are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ced763-5577-4359-8541-189286b328cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = em.YOLOWrapper({\"yolov8n\":yolov8n, \"yolov8s\":yolov8s},\n",
    "                      eval_model={\"yolov11n\":yolov11n},\n",
    "                      yolo_version={\"yolov8n\":8, \"yolov8s\":8, \"yolov11n\":11}, classnames=COCO_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864c9597-2e26-428e-ab79-992da580d6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e4fc012-6156-41c2-9963-7c2f62b152d8",
   "metadata": {},
   "source": [
    "## assemble the pipeline\n",
    "\n",
    "Take all of the steps we built above and assemble into a `Pipeline` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ca717a-ddc9-4876-ab46-da94d2cd7000",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = proofer+imp+aug+yolo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fda01b-036d-43b8-acd4-55896fcbedc4",
   "metadata": {},
   "source": [
    "## Write a loss function\n",
    "\n",
    "Since we passed a dictionary of models to `em.YOLOWrapper`, it will output a dictionary of results with the same keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14abe55a-c8d2-40c5-9a47-63d34b1c261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(output, **kwargs):\n",
    "    outdict = {}\n",
    "    # iterate over models\n",
    "    for k in output:\n",
    "        # pull out max detection score across classes for every batch element and box\n",
    "        maxdetect_boxes = output[k][0][:,:,4] # (batch, num_boxes)\n",
    "        maxdetect = torch.max(maxdetect_boxes, 1)[0]  # (batch,)\n",
    "        # let's also compute an average success rate (ASR) at 25%. mapping each batch\n",
    "        # element to 0 or 1 will give the ASR when averaged across the batch\n",
    "        asr25 = (maxdetect < 0.25).type(torch.float32)\n",
    "        # record the max detection for each batch element\n",
    "        outdict[f\"maxdetect_{k}\"] = maxdetect\n",
    "        outdict[f\"asr25_{k}\"] = asr25\n",
    "    return outdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893330cf-cce5-416c-9e08-f19838552e35",
   "metadata": {},
   "source": [
    "Pass the loss function to your pipeline along with a dictionary giving the shapes of a batch of test patches, so it can check the inputs/outputs before you start training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827eb019-d791-475e-a6a5-e90b358a1e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.set_loss(loss, test_patch_shape={k:(2,3,64,64) for k in ['hood', 'roof', 'door']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99581ab7-3b8f-4d87-939b-2149b71cba4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc93e4b1-b9fe-482d-b765-2c640a7b47c5",
   "metadata": {},
   "source": [
    "## Train the patch\n",
    "\n",
    "When we set logging- we can also add arbitrary key-value pairs two ways as keyword arguments to `pipeline.set_logging()`:\n",
    "\n",
    "* `extra_params` will add them as MLFlow parameters; this is useful for tracking exogenous variables when your pipeline is part of a larger experiment\n",
    "* `tags` will add them to as MLFlow tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2333bac-fb9a-4990-8830-2fe7dfce739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.set_logging(logdir=\"logs/06_ensemble\",\n",
    "                    mlflow_uri=\"http://127.0.0.1:5000\",\n",
    "                    experiment_name=\"electricmayhem_tutorial_06_ensemble_and_transfer\",\n",
    "                    extra_params={\"foo\":\"bar\"},\n",
    "                    tags={\"this_is_my_tag\":\"wow_it_totally_is\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6463354a-84a4-4c0c-b002-39fb9e6e072c",
   "metadata": {},
   "source": [
    "Second, explicitly tell it to initialize the patches. If you want you could alternatively pass it a dictionary of patches pre-initialized to whatever you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b40ed7-9198-4c40-ba66-444c95317ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.initialize_patch_params(patch_shape={k:(3,64,64) for k in ['hood', 'roof', 'door']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb53b19-4204-4aeb-b8b7-aaf7f5c06855",
   "metadata": {},
   "source": [
    "All of our classes inherit from `torch.nn.Module` so this should look familiar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f4ece5-c08f-48a1-9fdb-60bb88af9603",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.cuda();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d68594a-3d7d-4cb8-b610-341691cb328e",
   "metadata": {},
   "source": [
    "When training the patch- the loss function will return two `maxdetect` terms, one for each model, so we'll need to specify weights for each explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cb106c-0369-47c4-8f33-c75d7a5aae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch = pipeline.train_patch(\n",
    "    12,\n",
    "    1000,\n",
    "    learning_rate=0.01, \n",
    "    eval_every=100,\n",
    "    num_eval_steps=10,\n",
    "    optimizer='adam',\n",
    "    lr_decay='cosine',\n",
    "    maxdetect_yolov8n=0.5,\n",
    "    maxdetect_yolov8s=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6843263d-eb98-4443-ae78-1d3ec9d9921c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f05207-7b75-4232-8c56-bd732833f4f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f159182-82ec-496d-96e5-8db992038ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd199de-4f1f-4bfa-bab5-ef6eba792c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
