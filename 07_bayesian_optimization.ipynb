{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87c26d84-d3a8-445f-9250-cd1c6eef2c58",
   "metadata": {},
   "source": [
    "# Tutorial 07: Bayesian optimization\n",
    "\n",
    "In this notebook we'll take a first shot at reimagining CVPR2024's *Overload: Latency Attacks on Object Detection for Edge Devices* by Chen *et al* as a physical patch attack. \"Overload\" exploits the quadratic scaling of non-maximum suppression to try and slow the postprocessing phase of inference down by generating a lot of overlapping detections.\n",
    "\n",
    "We'll set up a pipeline for training a ground patch to generate false positives- but since what we really want is to slow NMS time, we'll run the pipeline iteratively and train a Gaussian process to predict the best parameter combinations for patch training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae98af7-ab14-45f6-9ad1-3584d28509d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import ultralytics\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb6463b-d9e9-4bdf-b393-7e0c49a0b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import electricmayhem.whitebox as em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b515f2d-27b6-4fe2-8b49-e6e88c6055c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_CLASSES = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',\n",
    "                'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench','bird', 'cat',\n",
    "                'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',\n",
    "                'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "                 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "                'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "                 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',\n",
    "                'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "                'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book',\n",
    "                'clock', 'vase', 'scissors', 'teddy bear', 'hair drier','toothbrush']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddc4dc5-9c1a-4483-a24e-552d942c4dd7",
   "metadata": {},
   "source": [
    "## create\n",
    "\n",
    "I'm starting with the guess that a tiled patch would be a cheap way to create minimally-overlapping detections (so that there are more detections that other detections have to be compared against)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc6a72d-e87b-4503-a113-94935e743cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_size = 256\n",
    "patch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808680f8-622e-4079-aa1d-a5d6cb5ce1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiler = em.PatchTiler({\"ground\":(tile_size, tile_size)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f122f04-2541-459c-8643-f6712d6bb72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "proofer = em.SoftProofer(\"data/profile.icc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1850c70d-2aeb-49c2-ba01-25a6a10cd4ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91c3e04f-d946-4efa-9175-e34ca48b8760",
   "metadata": {},
   "source": [
    "## implant\n",
    "\n",
    "Reuse the same target dataset from tutorial 01, but just the ground patch this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12147874-2a06-4260-99b1-f0dd118a2739",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"data/toycar/toycar_warp_dataset.csv\")\n",
    "labels = labels[labels.patch == \"ground\"]\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b46bbe-bba5-4d59-9989-e0950fb1f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bee5973-24b4-471e-a581-727ea68fe9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567738a3-b66a-4eb6-a51a-0c748c0b8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_shapes = {k:(3,patch_size, patch_size) for k in ['ground']}\n",
    "imp = em.WarpPatchImplanter(labels, patch_shapes=patch_shapes, dataset_name=\"toycar_warp_only_ground\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110320de-c592-4b0e-a4a4-c7d580f977f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8499553-ae01-4f9e-bc4e-14e707371c14",
   "metadata": {},
   "source": [
    "## compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f468ee-8800-43e8-aaa6-c74d656a704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = em.KorniaAugmentationPipeline({\"ColorJiggle\":{\"brightness\":0.2, \"contrast\":0.2, \"hue\":0.1, \"saturation\":0.1},\n",
    "                                    \"RandomAffine\":{\"scale\":(0.9,1.1), \"shear\":10, \"padding_mode\":\"reflection\", \"degrees\":0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfaa816-0c15-4e3f-849e-2f15768a3cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65122add-2036-4cb1-ae09-ec2221c491b5",
   "metadata": {},
   "source": [
    "## infer\n",
    "\n",
    "For this test I'll just use one model. Feel free to make this as complicated as you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e8667c-6c48-4130-9473-7000bde4b6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov8n = ultralytics.YOLO(\"yolov8n.pt\").model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1116eb5e-8142-4b61-a585-a1038ea9173f",
   "metadata": {},
   "source": [
    "One slight change to `em.YOLOWrapper` compared to other notebooks- let's raise the `iouthresh` kwarg, which **only** effects visualizations, so we can see how many boxes are actually created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ced763-5577-4359-8541-189286b328cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = em.YOLOWrapper(yolov8n, yolo_version=8, classnames=COCO_CLASSES, iouthresh=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864c9597-2e26-428e-ab79-992da580d6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e4fc012-6156-41c2-9963-7c2f62b152d8",
   "metadata": {},
   "source": [
    "## assemble the pipeline\n",
    "\n",
    "Take all of the steps we built above and assemble into a `Pipeline` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ca717a-ddc9-4876-ab46-da94d2cd7000",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = tiler+proofer+imp+aug+yolo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fda01b-036d-43b8-acd4-55896fcbedc4",
   "metadata": {},
   "source": [
    "## Write a loss function\n",
    "\n",
    "Note that in this case, success is when the patch is detected **above** 0.25 (the default minimum) instead of below. \n",
    "\n",
    "I think there are likely better loss terms than the ones I chose here; these are literally the first two things I thought of:\n",
    "\n",
    "* Finding the max detection score of each batch/box index, and taking the average value of `1-score`\n",
    "* Same as above but capping the max detection score at 0.3, so once a particular box is enough to get detected we don't try to get it higher\n",
    "\n",
    "If I really wanted to get an Overload patch working, this is probably where I'd spend some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66f859a-3240-4e3e-b767-128025e3a5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.3\n",
    "\n",
    "def loss(output, **kwargs):\n",
    "    maxdetect_boxes = output[0][:,:,4] # (batch, num_boxes)\n",
    "    maxdetect = torch.max(maxdetect_boxes, 1)[0]  # (batch,)\n",
    "\n",
    "    inverse_maxdetect = torch.mean(1-maxdetect_boxes, -1)\n",
    "    hard_threshold = torch.mean(1 - torch.minimum(maxdetect_boxes, torch.tensor(threshold)), -1)    \n",
    "\n",
    "    # how many boxes per image above the default detection threshold? this is a handy\n",
    "    boxcount = torch.sum((maxdetect_boxes >= 0.25).type(torch.float32), -1)\n",
    "\n",
    "    # run NMS, collecting a timestamp before and after so we can estimate the wall time. this is probably\n",
    "    # not a perfect estimate of NMS performance on a mobile device but the scaling should be the same.\n",
    "    with torch.no_grad():\n",
    "        detects = output[0].permute(0,2,1) # (batch, 5+num_classes, num_boxes)\n",
    "        detects = torch.concatenate([detects[:,:4,:], detects[:,5:,:]],1) # (batch, 4+num_classes, num_boxes)\n",
    "        t0 = time.time()\n",
    "        nms = ultralytics.utils.ops.non_max_suppression(detects, conf_thres=0.1)\n",
    "        t1 = time.time()\n",
    "\n",
    "    outdict = {\n",
    "        \"inverse_maxdetect\":inverse_maxdetect,\n",
    "        \"hard_threshold\":hard_threshold,\n",
    "        \"boxcount\":boxcount,\n",
    "        \"nms_time\":(t1-t0)*torch.ones_like(maxdetect)\n",
    "    }\n",
    "    return outdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893330cf-cce5-416c-9e08-f19838552e35",
   "metadata": {},
   "source": [
    "Pass the loss function to your pipeline along with a dictionary giving the shapes of a batch of test patches, so it can check the inputs/outputs before you start training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827eb019-d791-475e-a6a5-e90b358a1e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.set_loss(loss, test_patch_shape={k:(2,3,patch_size, patch_size) for k in ['ground']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99581ab7-3b8f-4d87-939b-2149b71cba4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc93e4b1-b9fe-482d-b765-2c640a7b47c5",
   "metadata": {},
   "source": [
    "## Train the patches\n",
    "\n",
    "The `pipeline.optimize()` method takes in most of the inputs you'd use to prepare a patch for training normally- logging directory, MLFlow location and experiment, and patch dimensions for initialization.\n",
    "\n",
    "After that, when you specify keyword arguments for training, you can replace any of them with an interval to tell `electricmayhem` to include them in a Gaussian process. The different ways you can specify variables to optimize:\n",
    "\n",
    "* A tuple with low and high values (`hard_threshold=(0,1)`)\n",
    "* A tuple with low and high values and \"log\" to sample on a logarithmic scale (`learning_rate=(1e-4, 1e-1, \"log\"),`)\n",
    "* A tuple with low and hight values and \"int\" to sample integer values (`accumulate=(1, 25, \"int\"),`)\n",
    "* A list of categorical values, such as for optimizer or LR decay (`optimizer=[\"adam\", \"mifgsm\"],`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f4ece5-c08f-48a1-9fdb-60bb88af9603",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c96f03-1b57-4d04-a801-98077dab2d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.optimize(\n",
    "    \"nms_time\", # this is the objective for the black-box optimization loop\n",
    "    \"logs_latency_attack/\",\n",
    "    {\"ground\":(3,patch_size, patch_size)},\n",
    "    1000, # number of experiments (I stopped after a few dozen)\n",
    "    2500, # budget of steps per experiment\n",
    "    24, # batch size\n",
    "    num_eval_steps=100,\n",
    "    mlflow_uri=\"http://127.0.0.1:5000\",\n",
    "    experiment_name=\"electricmayhem_tutorial_07_bayesian_optimization_2\",\n",
    "    extra_params={\"tile_size\":tile_size, \"pach_size\":patch_size},\n",
    "    minimize=False,\n",
    "    learning_rate=(1e-4, 1e-1, \"log\"),\n",
    "    lr_decay=\"cosine\",\n",
    "    optimizer=[\"adam\", \"mifgsm\"],\n",
    "    inverse_maxdetect=(0,1),\n",
    "    hard_threshold=(0,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d68594a-3d7d-4cb8-b610-341691cb328e",
   "metadata": {},
   "source": [
    "When training the patch- the loss function will return two `maxdetect` terms, one for each model, so we'll need to specify weights for each explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6843263d-eb98-4443-ae78-1d3ec9d9921c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b723d2-95f2-490d-bd4f-5cf08cb39155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7fa06d-9d36-4106-8915-6970f7d7ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2822f08-ee56-48d7-a428-c7ea0939562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ultralytics.utils.ops.non_max_suppression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ae0c9d-f354-42fa-b487-fe3550c51389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e5fc14-daf9-4602-b511-c435633e1128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f05207-7b75-4232-8c56-bd732833f4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ultralytics.utils.ops.non_max_suppression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f159182-82ec-496d-96e5-8db992038ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9660c3-b37a-4d31-920c-164a434433ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch[\"ground\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c211ab6f-9440-43df-85cd-ba4b739021f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo, _ = tiler({\"ground\":patch[\"ground\"].unsqueeze(0)}, evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca82f649-4864-47c1-b581-f559e07c5c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "em.plot(patch[\"ground\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba1fb0d-e7e4-4e8d-abdc-49fc8b3fecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "em.plot(foo[\"ground\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1ef4c5-dd0f-4d00-8fe8-b8ecfcb1974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo[\"ground\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd199de-4f1f-4bfa-bab5-ef6eba792c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ba806c-a447-48ed-a422-0c43289d23b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7822aee-4c35-4910-80d0-d3700958a00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-10,10,100)\n",
    "plt.plot(x, sig(x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33927f5-12ec-4dfb-a2d1-c4d6e548f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.minimum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99035109-8326-42b4-a02a-32759be4f356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
