{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87c26d84-d3a8-445f-9250-cd1c6eef2c58",
   "metadata": {},
   "source": [
    "# Tutorial 07: Bayesian optimization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae98af7-ab14-45f6-9ad1-3584d28509d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import ultralytics\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb6463b-d9e9-4bdf-b393-7e0c49a0b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import electricmayhem.whitebox as em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b515f2d-27b6-4fe2-8b49-e6e88c6055c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_CLASSES = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',\n",
    "                'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench','bird', 'cat',\n",
    "                'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',\n",
    "                'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "                 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "                'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "                 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',\n",
    "                'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "                'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book',\n",
    "                'clock', 'vase', 'scissors', 'teddy bear', 'hair drier','toothbrush']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddc4dc5-9c1a-4483-a24e-552d942c4dd7",
   "metadata": {},
   "source": [
    "## create\n",
    "\n",
    "Let's do color patches this time, but use a soft proofer during training to make sure the colors are realistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc6a72d-e87b-4503-a113-94935e743cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_size = 256\n",
    "patch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808680f8-622e-4079-aa1d-a5d6cb5ce1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiler = em.PatchTiler({\"ground\":(tile_size, tile_size)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f122f04-2541-459c-8643-f6712d6bb72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "proofer = em.SoftProofer(\"data/profile.icc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1850c70d-2aeb-49c2-ba01-25a6a10cd4ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91c3e04f-d946-4efa-9175-e34ca48b8760",
   "metadata": {},
   "source": [
    "## implant\n",
    "\n",
    "Reuse the same target dataset from tutorial 01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12147874-2a06-4260-99b1-f0dd118a2739",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"data/toycar/toycar_warp_dataset.csv\")\n",
    "labels = labels[labels.patch == \"ground\"]\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b46bbe-bba5-4d59-9989-e0950fb1f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bee5973-24b4-471e-a581-727ea68fe9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9980c810-5547-4851-adac-1f29bfce8330",
   "metadata": {},
   "source": [
    "Names of the 3 patches we'll train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6f0eca-bb1f-4aa9-8523-0a5ddb92db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.patch.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba60f27e-c516-4c7a-9885-7f079a59988d",
   "metadata": {},
   "source": [
    "The `em.WarpPatchImplanter()` class will take care of differentiably deforming and implanting patches (with kornia doing most of the heavy lifting). We need two inputs:\n",
    "\n",
    "* the `DataFrame` of target labels\n",
    "* a dictionary of patch shapes (at the point of implanting, so they'll be 3-channel); the implanter will use this to precompute transformation matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567738a3-b66a-4eb6-a51a-0c748c0b8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_shapes = {k:(3,patch_size, patch_size) for k in ['ground']}\n",
    "imp = em.WarpPatchImplanter(labels, patch_shapes=patch_shapes, dataset_name=\"toycar_warp_only_ground\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110320de-c592-4b0e-a4a4-c7d580f977f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8499553-ae01-4f9e-bc4e-14e707371c14",
   "metadata": {},
   "source": [
    "## compose\n",
    "\n",
    "The main tool `electricmayhem` has so far is `em.KorniaAugmentationPipeline()`, which just wraps the `kornia.augmentation` API. Initialize it with a dictionary of image augmentations, where each value is the keyword arguments that augmentation takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f468ee-8800-43e8-aaa6-c74d656a704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = em.KorniaAugmentationPipeline({\"ColorJiggle\":{\"brightness\":0.2, \"contrast\":0.2, \"hue\":0.1, \"saturation\":0.1},\n",
    "                                    \"RandomAffine\":{\"scale\":(0.9,1.1), \"shear\":10, \"padding_mode\":\"reflection\", \"degrees\":0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfaa816-0c15-4e3f-849e-2f15768a3cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65122add-2036-4cb1-ae09-ec2221c491b5",
   "metadata": {},
   "source": [
    "## infer\n",
    "\n",
    "Here's where we'll depart from tutorial 01. Let's train a patch using two YOLOv8 models and test performance on a YOLOv11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e8667c-6c48-4130-9473-7000bde4b6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov8n = ultralytics.YOLO(\"yolov8n.pt\").model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1116eb5e-8142-4b61-a585-a1038ea9173f",
   "metadata": {},
   "source": [
    "Pass dictionaries to `em.YOLOWrapper` to associate each model with a name (to make sure our logs are interpretable) as well as a YOLO version. In this case it won't matter because output formats of v8 and v11 are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ced763-5577-4359-8541-189286b328cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = em.YOLOWrapper(yolov8n, yolo_version=8, classnames=COCO_CLASSES, iouthresh=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864c9597-2e26-428e-ab79-992da580d6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e4fc012-6156-41c2-9963-7c2f62b152d8",
   "metadata": {},
   "source": [
    "## assemble the pipeline\n",
    "\n",
    "Take all of the steps we built above and assemble into a `Pipeline` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ca717a-ddc9-4876-ab46-da94d2cd7000",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = tiler+proofer+imp+aug+yolo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fda01b-036d-43b8-acd4-55896fcbedc4",
   "metadata": {},
   "source": [
    "## Write a loss function\n",
    "\n",
    "Note that in this case, success is when the patch is detected **above** 0.25 instead of below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66f859a-3240-4e3e-b767-128025e3a5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.3\n",
    "\n",
    "def loss(output, **kwargs):\n",
    "    maxdetect_boxes = output[0][:,:,4] # (batch, num_boxes)\n",
    "    maxdetect = torch.max(maxdetect_boxes, 1)[0]  # (batch,)\n",
    "\n",
    "    inverse_maxdetect = torch.mean(1-maxdetect_boxes, -1)\n",
    "    hard_threshold = torch.mean(1 - torch.minimum(maxdetect_boxes, torch.tensor(threshold)), -1)    \n",
    "\n",
    "    # how many boxes per image above the default detection threshold?\n",
    "    boxcount = torch.sum((maxdetect_boxes >= 0.25).type(torch.float32), -1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        detects = output[0].permute(0,2,1) # (batch, 5+num_classes, num_boxes)\n",
    "        detects = torch.concatenate([detects[:,:4,:], detects[:,5:,:]],1) # (batch, 4+num_classes, num_boxes)\n",
    "        t0 = time.time()\n",
    "        nms = ultralytics.utils.ops.non_max_suppression(detects, conf_thres=0.1)\n",
    "        t1 = time.time()\n",
    "\n",
    "    outdict = {\n",
    "        \"inverse_maxdetect\":inverse_maxdetect,\n",
    "        \"hard_threshold\":hard_threshold,\n",
    "        \"boxcount\":boxcount,\n",
    "        \"nms_time\":(t1-t0)*torch.ones_like(maxdetect)\n",
    "    }\n",
    "    return outdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893330cf-cce5-416c-9e08-f19838552e35",
   "metadata": {},
   "source": [
    "Pass the loss function to your pipeline along with a dictionary giving the shapes of a batch of test patches, so it can check the inputs/outputs before you start training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827eb019-d791-475e-a6a5-e90b358a1e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.set_loss(loss, test_patch_shape={k:(2,3,patch_size, patch_size) for k in ['ground']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99581ab7-3b8f-4d87-939b-2149b71cba4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc93e4b1-b9fe-482d-b765-2c640a7b47c5",
   "metadata": {},
   "source": [
    "## Train the patch\n",
    "\n",
    "When we set logging- we can also add arbitrary key-value pairs two ways as keyword arguments to `pipeline.set_logging()`:\n",
    "\n",
    "* `extra_params` will add them as MLFlow parameters; this is useful for tracking exogenous variables when your pipeline is part of a larger experiment\n",
    "* `tags` will add them to as MLFlow tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2333bac-fb9a-4990-8830-2fe7dfce739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline.set_logging(logdir=\"logs_07/08\",\n",
    "#                    mlflow_uri=\"http://127.0.0.1:5000\",\n",
    "#                    experiment_name=\"electricmayhem_tutorial_07_bayesian_optimization\",\n",
    "#                    extra_params={\"tile_size\":tile_size, \"pach_size\":patch_size})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6463354a-84a4-4c0c-b002-39fb9e6e072c",
   "metadata": {},
   "source": [
    "Second, explicitly tell it to initialize the patches. If you want you could alternatively pass it a dictionary of patches pre-initialized to whatever you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b40ed7-9198-4c40-ba66-444c95317ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline.initialize_patch_params(patch_shape={k:(3,patch_size, patch_size) for k in ['ground']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb53b19-4204-4aeb-b8b7-aaf7f5c06855",
   "metadata": {},
   "source": [
    "All of our classes inherit from `torch.nn.Module` so this should look familiar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f4ece5-c08f-48a1-9fdb-60bb88af9603",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c96f03-1b57-4d04-a801-98077dab2d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.optimize(\n",
    "    \"nms_time\",\n",
    "    \"logs_latency_attack/\",\n",
    "    {\"ground\":(3,patch_size, patch_size)},\n",
    "    1000,\n",
    "    2500,\n",
    "    24,\n",
    "    num_eval_steps=100,\n",
    "    mlflow_uri=\"http://127.0.0.1:5000\",\n",
    "    experiment_name=\"electricmayhem_tutorial_07_bayesian_optimization_2\",\n",
    "    extra_params={\"tile_size\":tile_size, \"pach_size\":patch_size},\n",
    "    minimize=False,\n",
    "    learning_rate=(1e-4, 1e-1, \"log\"),\n",
    "    lr_decay=\"cosine\",\n",
    "    optimizer=[\"adam\", \"mifgsm\"],\n",
    "    inverse_maxdetect=(0,1),\n",
    "    hard_threshold=(0,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d68594a-3d7d-4cb8-b610-341691cb328e",
   "metadata": {},
   "source": [
    "When training the patch- the loss function will return two `maxdetect` terms, one for each model, so we'll need to specify weights for each explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6843263d-eb98-4443-ae78-1d3ec9d9921c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b723d2-95f2-490d-bd4f-5cf08cb39155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7fa06d-9d36-4106-8915-6970f7d7ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2822f08-ee56-48d7-a428-c7ea0939562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ultralytics.utils.ops.non_max_suppression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ae0c9d-f354-42fa-b487-fe3550c51389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e5fc14-daf9-4602-b511-c435633e1128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f05207-7b75-4232-8c56-bd732833f4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ultralytics.utils.ops.non_max_suppression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f159182-82ec-496d-96e5-8db992038ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9660c3-b37a-4d31-920c-164a434433ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch[\"ground\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c211ab6f-9440-43df-85cd-ba4b739021f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo, _ = tiler({\"ground\":patch[\"ground\"].unsqueeze(0)}, evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca82f649-4864-47c1-b581-f559e07c5c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "em.plot(patch[\"ground\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba1fb0d-e7e4-4e8d-abdc-49fc8b3fecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "em.plot(foo[\"ground\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1ef4c5-dd0f-4d00-8fe8-b8ecfcb1974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo[\"ground\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd199de-4f1f-4bfa-bab5-ef6eba792c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ba806c-a447-48ed-a422-0c43289d23b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7822aee-4c35-4910-80d0-d3700958a00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-10,10,100)\n",
    "plt.plot(x, sig(x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33927f5-12ec-4dfb-a2d1-c4d6e548f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.minimum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99035109-8326-42b4-a02a-32759be4f356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
