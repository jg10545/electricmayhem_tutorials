{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73890ef6-059c-4294-9d35-d79211a0000a",
   "metadata": {},
   "source": [
    "# Tutorial 03: overview of **implant** stages\n",
    "\n",
    "Every experiment will have a stage where a patch or patches are implanted in a target image.\n",
    "\n",
    "Most of the implanting tools in `electricmayhem` input a pandas `DataFrame` object that gives the top, bottom, left, and right pixel values for a region for each patch in each target image. In multi-patch experiments it expects each patch to appear in each image.\n",
    "\n",
    "The `em.WarpPatchImplanter()` class works a bit differently- it inputs a `DataFrame` that gives x and y coordinates of where each corner of the patch should go in the target image, and differentiably distorts, rescales, and rotates the patch to fit. It can handle datasets where not every patch is in every image, as well as implanting the same image multiple times in the same target. This flexibility comes at the cost of some overheard, however, and varying numbers of patches per target can cause the memory footprint to vary during training. Use with caution!!\n",
    "\n",
    "When building dataframes for either type of implanter:\n",
    "\n",
    "* To build a multi-patch dataset, include a \"patch\" column specifying which patch goes in which box.\n",
    "* A \"split\" column that can take values \"train\" or \"eval\" will tell the implanter which target images to use during training and evaluation. If you leave this column out it will use the same images for each. I would advise against it though.\n",
    "* A hash digest of the dataframe will get logged to MLflow, so you'll be able to identify which runs are associated with which version of your labels. An optional `dataset_name` kwarg can make it much easier to interpret the logs.\n",
    "\n",
    "All implanters in `electricmayhem` can handle masked and translucent patches by specifying a `mask` argument. Pass a float between 0 and 1 to make the patch semitransparent or an image (with same dimensions as the patch) to use as a mask. In the multi-patch case use a dictionary to specify a float or mask for each patch separately. These masks and alpha values are fixed; I don't currently have a capability to do mask learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6937a30d-17dd-4e50-bdaa-27ee9b68693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import electricmayhem.whitebox as em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215f7edd-6a96-4d4a-b57d-46056049a822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44a7d131-c641-416a-b3d4-9627d234ec75",
   "metadata": {},
   "source": [
    "Load a test image and a test mask..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4132e5-11b3-422a-95fe-a51f7fdd7dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "flower = em.load_to_tensor(Image.open(\"data/flower2.png\").resize((32,24)))\n",
    "em.plot(flower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e85837a-d5e6-4cff-8e12-50bad92baf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = em.load_to_tensor(Image.open(\"data/masks/jolly_roger.png\").resize((32,24)))\n",
    "em.plot(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ca0195-4be5-4e29-a9b8-9791ef22ab02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aec352ef-881f-40ce-b3cc-698ec8035dbf",
   "metadata": {},
   "source": [
    "## Rectangle Implanters\n",
    "\n",
    "There are currently three versions implemented, for slightly different applications\n",
    "\n",
    "* `em.ScaleToBoxRectanglePatchImplanter` resizes each patch to the label box\n",
    "* `em.FixedRatioRectanglePatchImplanter` resizes each patch to a fixed fraction of the dimensions of the label box and implants randomly within the box\n",
    "* `em.RectanglePatchImplanter` resizes each patch by a random scale **not** determined by the box before implanting\n",
    "\n",
    "We'll use `em.ScaleToBoxRectanglePatchImplanter` here but the API is pretty similar for all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082fc276-dd58-4cc8-a87a-8b9225b1bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rect = pd.read_csv(\"data/toycar/toycar_rect_dataset.csv\")\n",
    "len(df_rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc80515-a7c4-4ebd-af34-7d061999d5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2ce8f7-a358-47b4-a2b4-9a85cd4f3e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = em.ScaleToBoxRectanglePatchImplanter(df_rect, dataset_name=\"toycar_rect_no_ground\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f958fda-2997-4e41-8914-682ec67d8e3e",
   "metadata": {},
   "source": [
    "All of the implanters have a `plot_boxes()` method you can use for a quick visual check on your labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d177fb50-61fd-45b6-a8be-3e7bd71b73ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.plot_boxes();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a35610-e7f0-4722-8919-0798111dd7bc",
   "metadata": {},
   "source": [
    "Now let's make a batch of patches, pass through the implanter and visualize the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09795ee-f9e4-4d66-a9bf-b296d74f7cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_batch = {k:flower.unsqueeze(0) for k in [\"hood\", \"roof\"]}\n",
    "implanted, _ = imp(patch_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ed49ad-ceeb-4ab2-af0b-b6019cabb5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "em.plot(implanted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00d91cf-8679-446f-8d7f-3f951ada612b",
   "metadata": {},
   "source": [
    "After any time we call the implanter, we can get a JSON-serializable dictionary containing all the sampled parameters using the `get_last_sample_as_dict()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b0118b-996e-4c16-886b-deb50d623e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.get_last_sample_as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3a9cb5-46ee-4c79-be73-cac9dd352125",
   "metadata": {},
   "source": [
    "### Now with masking\n",
    "\n",
    "All implanters can accept three types of inputs for masking:\n",
    "\n",
    "* A float representing an alpha value between `0` (transparent) and `1` (opaque)\n",
    "* A grayscale tensor the same dimensions as the patch\n",
    "* A dictionary mapping patch names to either of the above\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090eda58-5775-4f88-96aa-fece792eaa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = em.ScaleToBoxRectanglePatchImplanter(df_rect, mask={\"hood\":1-mask, \"roof\":0.75}, dataset_name=\"toycar_rect_no_ground\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daf9f99-84ad-435c-afa3-b9b6487ff942",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_batch = {k:flower.unsqueeze(0) for k in [\"hood\", \"roof\"]}\n",
    "implanted, _ = imp(patch_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2efb3-3b24-4144-a23d-60966cdd34d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "em.plot(implanted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e3e5ea-87a3-483c-ba10-a35fa2c4d9da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c24a574-6cb1-4648-a45a-639dd13a007b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56443986-6da3-499a-853c-a46f49ff3ef6",
   "metadata": {},
   "source": [
    "## Warp implanter\n",
    "\n",
    "Currently only one implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5169fafd-bfc3-4335-877c-d618efe90e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_warp = pd.read_csv(\"data/toycar/toycar_warp_dataset.csv\")\n",
    "len(df_warp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f38de1-35c3-4d21-91c8-55e93396b7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_warp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed59e79-34f2-4b42-9786-83d0232401a2",
   "metadata": {},
   "source": [
    "The constructor for `em.WarpPatchImplanter` requires you to give the dimensions for each patch- it'll use this to precompute transformation matrices for each patch/target combination. For large datasets this might take a few minutes but significantly speeds up training.\n",
    "\n",
    "Unlike the box implanters, this one keeps the target images on the CPU and only copies them over a batch at a time. This adds a bit of overhead but makes it practical to train with large target datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f157577c-dea8-4386-b101-859709018f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "flower = em.load_to_tensor(Image.open(\"data/flower2.png\").resize((64,48)))\n",
    "mask = em.load_to_tensor(Image.open(\"data/masks/jolly_roger.png\").resize((64,48)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6903543-bfc1-4b27-a70d-c123ae4c1895",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = em.WarpPatchImplanter(df_warp, \n",
    "                            patch_shapes={k:(3,48,64) for k in [\"ground\", \"hood\", \"roof\", \"door\"]},\n",
    "                            mask={\"ground\":mask, \"hood\":1-mask, \"roof\":1, \"door\":1},\n",
    "                            dataset_name=\"toycar_warp_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b14feb6-db4e-485e-9c1f-c156605b70a9",
   "metadata": {},
   "source": [
    "Note the difference in how dimensions are specified here (pytorch CHW format) versus how we resized the image with PIL (WH) above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c8aa1e-4048-4edd-aa7e-cddfc3823f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.plot_boxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da96b60d-f28c-47d9-a744-f238d82c07d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_batch = {k:flower.unsqueeze(0) for k in [\"hood\", \"roof\", \"ground\", \"door\"]}\n",
    "implanted, _ = imp(patch_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f72ca4f-c81b-472d-86b2-bdd9cf5ea91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "em.plot(implanted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c349b1-88a6-491c-a4ac-69a6b2e8ffe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
